setwd("D:\Git\TrendMining")
setwd("D:/Git/TrendMining")
getwd()
#** Set your work directory to the TrendMining project directory (where the script file are)
#** A folder "data" will be created for saving files (if such folder does not exist)
#** EDIT THE FOLLOWING LINE, set your own work directory
#setwd("K:/My Documents/Projects/TrendMining_2017/TrendMining")
setwd("D:/Git/TrendMining")
my_work_dir = getwd()
my_data_dir = "data"
if (!file.exists(my_data_dir)) {
dir.create(file.path(my_work_dir, my_data_dir))
}
#** STACKOVERFLOW API KEY
#** Set your own StackOverflow API key here (or use the default below)
#** EDIT THE FOLLOWING LINE for your own API key
#api_key = "9raZ36FkYGFHDSNrW)gdsw((" TODO old file name edit out
so_api_key = "Qa0f*SDU36j)7KMJbAu)Nw(("
#** GETOLDTWEETS-JAVA PATH
#** Set path to the directory for "GetOldTweets-java-master"
getoldtweets_path = paste(getwd(),"/GetOldTweets-java-master", sep="")
#** SCOPUS API KEY
#** Set your own Scopus API key here
#** Create an account & create your API key => <your-own-scopus-api-key>
#** https://dev.elsevier.com/user/login
#** Replace the next line with set_api_key("YOUR_SCOPUS_KEY_HERE")
#** EDIT THE FOLLOWING LINE with YOUR OWN Scopus API key
#install.packages("rscopus", dependencies = TRUE)
library("rscopus")
sc_api_key = "5adc613940574a3639f109e6f1a2742a"
# set_api_key("cbf4132ececcb84b58a2aa5244ba7ce7")
# set_api_key("cbf4132ececcb84b58a2aa5244ba7ce7")
#alternatively you may store it a personal file somewhere else.
# set_api_key("cbf4132ececcb84b58a2aa5244ba7ce7")
#alternatively you may store it a personal file somewhere else.
#source("~/ETiSEngineering/TrendMining-master/SetScopusApiKey.R")
# install.packages("text2vec", dependencies = TRUE)
library("text2vec")
source("FunctionsScopusApi.R")
install.packages("text2vec", dependencies = TRUE)
library("text2vec")
install.packages("text2vec", dependencies = TRUE)
install.packages("text2vec", dependencies = TRUE)
library("text2vec")
source("FunctionsScopusApi.R")
set_api_key("cbf4132ececcb84b58a2aa5244ba7ce7")
# my_query_string = "botnet"
query_string = "botnet"
my_filename = "botnet-sco"
my_query_string = "TITLE-ABS-KEY(\""
my_query_string = paste(my_query_string, query_string, sep="")
#EDIT this line
#  my_query_string = paste(my_query_string, "\") AND ALL('software testing')", sep="")
my_query_string = paste(my_query_string, "\") AND ALL('software')", sep="")
#Get articles and save those - we do not want to re-run the query
my_articles = get_scopus_papers(my_query_string)
#Remove copyright sign.
abstract = my_articles$Abstract
abstract = gsub("Copyright ?+[^.]*[.]","",abstract)
abstract = gsub("?+[^.]*[.]","",abstract) # Depdenging on the enviroment or data you might need something different*
abstract = gsub("All rights reserved[.]","",abstract)
abstract = gsub("All right reserved[.]","",abstract)
abstract = gsub("No abstract available[.]","",abstract)
abstract = gsub("[0-9]", "", abstract)
#It is easy to accidentally too much or too little.
#Check length of abstracts -> ratio of new vs origal
nchar(abstract)/nchar(my_articles$Abstract)
mean (nchar(abstract)/nchar(my_articles$Abstract), na.rm=TRUE)
abstract[nchar(abstract)/nchar(my_articles$Abstract)<0.5]
#Add cleaned abstracts as a NEW column.
#We could also replace the existing but debugging is easier if we keep both.
my_articles$Abstract_clean = tolower(abstract)
my_articles$Title = tolower(my_articles$Title)
#Remove papers that are summaries of conference proceedings.
#If check needed otherwise 0 would remove all papers.
if (length(grep("proceedings contain", my_articles$Abstract_clean, ignore.case = TRUE)) > 0){
my_articles = my_articles[-grep("proceedings contain", my_articles$Abstract_clean, ignore.case = TRUE),]
}
#Date is character convert to Date object
my_articles$Date = as.Date(my_articles$Date)
#Fixed filename: /data/my_scopus_<my_filename>_data.RData
my_file = my_work_dir
my_file = paste(my_file, "/data/my_Scopus_", sep="", collapse=" ")
my_file = paste(my_file, my_filename, sep="", collapse=" ")
my_file = paste(my_file, "_data.RData", sep="", collapse=" ")
save(my_articles, file=my_file)
